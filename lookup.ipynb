{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multivec.cython.multivec import BilingualModel, MonolingualModel\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 3.33 s, total: 14.9 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpora = [b\"./un16m.bin\", b'./un4m.lemma.bin']\n",
    "corpus = corpora[0]\n",
    "model = BilingualModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = model.src_model\n",
    "zh_model = model.trg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'governments | institutions | industrialized | developing | national | regions | neighbouring | subnational | region | regional | capacities | recipient | less-developed | ownership | middle-income | neighboring | Industrialized | strategies | sovereign | economies'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = '國家' # '資產' # '獲益' #'餵奶' # \n",
    "enlist = model.src_closest(w.encode(), n=20)\n",
    "' | '.join([e.decode() for (e, d) in enlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['敏鋭', '氣質', '好奇心', '社會意識', '認知', '特質', '敏感性', '道德觀念', '自我認識', '理解力', '敏感度', '激發起', '思想道德', '感性', '覺悟', '政治覺悟', '解構', '感知', '積極向上', '表達能力']\n"
     ]
    }
   ],
   "source": [
    "w = 'sensibility'\n",
    "zhlist = model.trg_closest(w.encode(), n=20)\n",
    "print([z.decode() for (z, d) in zhlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(w1, w2, w3):\n",
    "    '''\n",
    "    Solves problems of the type:\n",
    "    w1 : w2 :: w3 : __\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.src_model.word_vec(w1.encode())\n",
    "        w2v = model.src_model.word_vec(w2.encode())\n",
    "        w3v = model.trg_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.trg_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scotland : Edinburgh :: 英格蘭 : 愛丁堡\n",
      "['愛丁堡', '劍橋', '加的夫', '愛丁堡大學', '諾丁漢', '七海', '曼徹斯特', '格拉斯哥', '新澤西', '達拉斯', '英國倫敦', '約克郡', '鹽湖城', '利物浦']\n"
     ]
    }
   ],
   "source": [
    "w1 = 'Scotland'\n",
    "w2 = 'Edinburgh'\n",
    "w3 = '英格蘭'; \n",
    "analogy(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'國王 | 賈南 | 皇帝 | 之王 | 國父 | 一世 | 統治者 | 公爵 | 諾羅敦 | 陛下 | 托亞 | 登基 | 王室 | 君主 | 女皇 | 大公 | 王朝 | 敬愛 | 女王 | 塔努馬'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'king'\n",
    "zhlist = model.trg_closest(w.encode(), n=20)\n",
    "' | '.join([z.decode() for (z, d) in zhlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy2(w1, w2, w3):\n",
    "    '''\n",
    "    Solves problems of the type:\n",
    "    w1 : w2 :: w3 : __\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.trg_model.word_vec(w1.encode())\n",
    "        w2v = model.trg_model.word_vec(w2.encode())\n",
    "        w3v = model.src_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.src_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine | life | imprisonment | living | live | lives | fines | people | citizens | lived | fined | kip | 20.000.000 | citizen | perpétua | RM10 | inhabitants | 5.000.000 | riel | families | person | Rp | rupees | dong | man\n"
     ]
    }
   ],
   "source": [
    "# adj-modifier [JJ] (w2) + noun [NO] (w1)\n",
    "w1 = '疾病'\n",
    "w2 = '先天'\n",
    "w3 = 'disease'\n",
    "# adv-modifier (w2) + verb (w1)\n",
    "w1 = '氣候'\n",
    "w2 = '正常'\n",
    "w3 = 'phenomenon'\n",
    "\n",
    "w1 = '男'\n",
    "w2 = '國王'\n",
    "w3 = 'woman'\n",
    "\n",
    "# base=N, collocate=V\n",
    "w1 = '根基'# '根本'\n",
    "w2 = '鞏固' #'動搖'\n",
    "w3 = 'foundations'\n",
    "\n",
    "# base=N, collocate=V\n",
    "w1 = '秘密'# '根本'\n",
    "w2 = '發現' #'動搖'\n",
    "w3 = 'secrets'\n",
    "\n",
    "# base=N, collocate=V\n",
    "w1 = '人選'# '根本'\n",
    "w2 = '推薦' #'動搖'\n",
    "w3 = 'candidate'\n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = '犯罪'\n",
    "w2 = '打擊'\n",
    "w3 = 'crime'; \n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = '耕耘'\n",
    "w2 = '默默'\n",
    "w3 = 'work'; \n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = '名譽'\n",
    "w2 = '損害'\n",
    "w3 = 'reputation'; \n",
    "\n",
    "w1 = '隱私'\n",
    "w2 = '侵犯'\n",
    "w3 = 'privacy'; \n",
    "\n",
    "w1 = '精緻'\n",
    "w2 = '生活'\n",
    "w3 = 'fine'; \n",
    "\n",
    "w1v = zh_model.word_vec(w1.encode())\n",
    "w2v = zh_model.word_vec(w2.encode())\n",
    "w3v = en_model.word_vec(w3.encode())\n",
    "w4v = w3v + (w2v - w1v)\n",
    "closest_words = [w.decode() for (w, d) in en_model.closest_to_vec(w4v, n=25)]\n",
    "print(' | '.join(closest_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'fine', 0.71402907371521),\n",
       " (b'life', 0.6275485157966614),\n",
       " (b'imprisonment', 0.5957995653152466),\n",
       " (b'living', 0.5903329253196716),\n",
       " (b'live', 0.5238180160522461),\n",
       " (b'lives', 0.521121621131897),\n",
       " (b'fines', 0.5015294551849365),\n",
       " (b'people', 0.48274001479148865),\n",
       " (b'citizens', 0.46281448006629944),\n",
       " (b'lived', 0.45351529121398926),\n",
       " (b'fined', 0.4439633786678314),\n",
       " (b'kip', 0.4424514174461365),\n",
       " (b'20.000.000', 0.4390920400619507),\n",
       " (b'citizen', 0.43767303228378296),\n",
       " (b'perp\\xc3\\xa9tua', 0.4332098662853241),\n",
       " (b'RM10', 0.4323761463165283),\n",
       " (b'inhabitants', 0.4301243722438812),\n",
       " (b'5.000.000', 0.4230095446109772),\n",
       " (b'riel', 0.42221710085868835),\n",
       " (b'families', 0.4221489727497101),\n",
       " (b'person', 0.42182105779647827),\n",
       " (b'Rp', 0.42133381962776184),\n",
       " (b'rupees', 0.41881904006004333),\n",
       " (b'dong', 0.4179326891899109),\n",
       " (b'man', 0.4169285297393799)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " en_model.closest_to_vec(w4v, n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocate(w1, w2, w3):\n",
    "    '''\n",
    "    Given:\n",
    "        Chinese base w1 and Chinese collocate w2\n",
    "    Find:\n",
    "        candidates for collocate to English base w3\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.trg_model.word_vec(w1.encode())\n",
    "        w2v = model.trg_model.word_vec(w2.encode())\n",
    "        w3v = model.src_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.src_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "犯罪 : 打擊 :: crime : combating\n",
      "['combating', 'fight', 'combat', 'terrorism', 'trafficking', 'corruption', 'COMBATING', 'combatting', 'Combatting', 'prevention', 'Combating', 'scourge', 'suppression', 'anti-trafficking']\n"
     ]
    }
   ],
   "source": [
    "# adj-modifier [JJ] (w2) + noun [NO] (w1)\n",
    "w1 = '貧窮'\n",
    "w2 = ''\n",
    "w1 = '疾病'\n",
    "w2 = '治療'\n",
    "w3 = 'disease'\n",
    "w3 = 'poverty'\n",
    "\n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = '因素'\n",
    "w2 = '確定'\n",
    "w3 = 'factors'\n",
    "\n",
    "w1 = '犯罪'\n",
    "w2 = '打擊'\n",
    "w3 = 'crime'\n",
    "collocate(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocate2(w1, w2, w3):\n",
    "    '''\n",
    "    Given:\n",
    "        Chinese base w1 and Chinese collocate w2\n",
    "    Find:\n",
    "        candidates for collocate to English base w3\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.src_model.word_vec(w1.encode())\n",
    "        w2v = model.src_model.word_vec(w2.encode())\n",
    "        w3v = model.trg_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.trg_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victim : abuse :: 受害者 : 虐待\n",
      "['虐待', '性虐待', '剝削', '性暴力', '濫用', '性侵犯', '暴力', '欺凌', '凌辱', '凌虐', '暴力行為', '虐待老人', '性', '家庭暴力']\n"
     ]
    }
   ],
   "source": [
    "w1 = 'victim'\n",
    "w2 = 'prominent'\n",
    "w3 = '犧牲者'\n",
    "\n",
    "w1 = 'victim'\n",
    "w2 = 'abuse'\n",
    "w3 = '受害者'\n",
    "\n",
    "collocate2(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09458018600005236"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine as cos_dist\n",
    "cos_dist(model.src_model.word_vec('disease'.encode()), \n",
    "         model.trg_model.word_vec('疾病'.encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "策略 : 嚴厲 :: tactic : harsher\n",
      "['harsher', 'harshest', 'sanction', 'punishments', 'severest', 'draconian', 'merciless', 'crackdowns', 'harshly', 'punishment', 'brutal', 'ruthless', 'shamelessly', 'callously']\n"
     ]
    }
   ],
   "source": [
    "w1 = '策略' \n",
    "w2 = '嚴厲'  \n",
    "w3 = 'tactic'\n",
    "analogy2(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision : light :: 決定 : 有鑒於\n",
      "['有鑒於', '鑒於', '銘記', '考慮', '牢記', '加以分析', '無先例', '審慎考慮', '宜于', '審視', '到現', '時局', '須予', '參照', '過高估計']\n"
     ]
    }
   ],
   "source": [
    "w3 = 'execution'\n",
    "w1 = 'rank' \n",
    "w2 = 'prioritize'  \n",
    "\n",
    "w1 = 'decision' \n",
    "w2 = 'light'  \n",
    "w3 = '決定'\n",
    "analogy(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en_model.sent_vec(b'Hong Kong') - en_model.word_vec(b'Hong') - en_model.word_vec(b'Kong')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en2zh(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.trg_closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval\n",
    "\n",
    "def zh2en(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.src_closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enSynonyms(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.src_model.closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval\n",
    "\n",
    "def zhSynonyms(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.trg_model.closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英語近義詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'incipient | embryo | infancy | cloned | immature | formative | skeletal | embryos | quails | metabolism | aberration | hepatic | vivo | hypodynamy | germination | vitro | maturation | chromosomal | primitive | hormones | organism | microscopic | inhibitor | germ | hormone'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = '''\n",
    "embryonic \n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(enSynonyms(words[-1], n=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'投機者 | 投機性 | 多國公司 | 掠奪性 | 爭先恐後 | 寡頭 | 擠走 | 投機 | 拉動 | 自然而然 | 拋售 | 有權有勢 | 接二連三 | 爭相 | 從眾 | 套利 | 壓低 | 出人意料 | 非正統 | 不擇手段 | 擠出 | 市場化 | 壟斷市場 | 投資商 | 貪得無厭'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = '''\n",
    "一窩蜂\n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(zhSynonyms(words[-1], n=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His flamboyant present overwrites his distressing past. It’s the eternal sunshine of the spotless Trump.\n",
      "他招搖過市的當下，遮蓋了他\u001b[01;31m\u001b[K不堪回首\u001b[m\u001b[K的過往——完美無瑕的特朗普閃出永恆的光。\n",
      "\u001b[36m\u001b[K--\u001b[m\u001b[K\n",
      "Today, Kiel is still a seafaring town. Submarines are still built here. Sailors bob on Kiel Sound. Instead of dreadnoughts and battle cruisers, hulking cruise and cargo ships dominate the urban shoreline. But the city is a mosaic of ill-matched architecture and buildings that have changed purpose. Wilhelm’s proud Naval Academy, for instance, is now the parliamentary seat of Schleswig-Holstein, the state of which Kiel is the capital. The mishmash lends a defeated air to a place still pondering how to remember and interpret a dreadful 20th century.\n",
      "今天的基爾，依然是座港口城市。潛水艇還在這裡建造。一群群水手徜徉在基爾的海灣。不同於昔日滿眼無畏艦、巡洋戰艦的場景，今天，龐大的遊船、貨船佔據着這座城市的海岸線。這裡的建築年代、風格迥異，早已遠離了舊日的各種用途。比如，威廉二世當年威風凜凜的海軍學院，如今已成為石勒蘇益格-荷爾斯泰因州（Schleswig-Holstein，首府為基爾）的議會大樓。如此古今交疊的混雜，給這座仍然對\u001b[01;31m\u001b[K不堪回首\u001b[m\u001b[K的20世紀試圖進行反思和詮釋的城市，籠罩了一種迷茫與挫敗的氛圍。\n",
      "\u001b[36m\u001b[K--\u001b[m\u001b[K\n",
      "Germany, however, an island of prosperity, is spending heavily to find ways out of the doom-and-gloom predictions, and it would seem ideally placed to show the Continent the way. So far, though, even while spending $265 billion a year on family subsidies, Germany has proved only how hard it can be. That is in part because the solution lies in remaking values, customs and attitudes in a country that has a troubled history with accepting immigrants and where working women with children are still tagged with the label “raven mothers,” implying neglectfulness.\n",
      "\\r不過，作為一座繁榮的經濟孤島，德國正斥巨資來尋找擺脫這一沮喪未來的方法，它似乎最有可能為歐洲大陸指條明路。然而到目前為止，儘管在家庭補貼上每年花費2650億美元（約合16218億元人民幣），德國也只是證明了這個問題有多麼難纏。這部分是因為解決方案關乎重塑這個國家的價值觀、習俗和態度，該國在接納移民上有一段\u001b[01;31m\u001b[K不堪回首\u001b[m\u001b[K的歷史，有孩子的職業女性仍被貼上「烏鴉媽媽」的標籤，意思是她們忽視了孩子。\n",
      "\u001b[36m\u001b[K--\u001b[m\u001b[K\n",
      "Given their bad experiences with domestic spying, first under the Nazis and then the former the East German secret police, Germans are touchy when it comes to issues of personal privacy and protection of their personal data. Guarantees ensuring the privacy of mail and all forms of long-distance communications are enshrined in Article 10 of their Constitution.\n",
      "\\r考慮到德國在國內監控這方面\u001b[01;31m\u001b[K不堪回首\u001b[m\u001b[K的歷史（先是納粹的監控，然後是前東德秘密警察的監控），德國人對個人隱私和個人數據保護等問題相當敏感。德國憲法的第10條莊嚴規定郵件和各種形式的長途通訊的隱私須得以確保。\n",
      "\u001b[36m\u001b[K--\u001b[m\u001b[K\n",
      "Van der Kolk began as he often does, with a personal anecdote. “My mother was very unnurturing and unloving,” he said. “But I have a full memory and a complete sense of what it is like to be loved and nurtured by her.” That’s because, he explained, he had done the very exercise that we were about to try on Eugene. Here’s how it would work: Eugene would recreate the trauma that haunted him most by calling on people in the room to play certain roles. He would confront those people — with his anger, sorrow, remorse and confusion — and they would respond in character, apologizing, forgiving or validating his feelings as needed. By projecting his “inner world” into three-dimensional space, Eugene would be able to rewrite his troubled history more thoroughly than other forms of role-play therapy might allow. If the experiment succeeded, the bad memories would be supplemented with an alternative narrative — one that provided feelings of acceptance or forgiveness or love.\n",
      "像過去一樣，范德科爾克的治療從講述自己的親身經歷開始。「我的母親對我毫無教養和疼愛之心，」他說。「但我卻能讓自己體會到在她關愛和撫育下成長的全部感受，並讓它們成為我的『記憶』。」因為他做過一項非常特別的練習，他解釋道，而這也正是現在尤金將要嘗試的。具體的做法是這樣的：在場的人們將應尤金的要求扮演各種特定的角色，從而幫助他重現那段深深困擾他的創傷。他將對着這些人表露他的憤怒、悲傷、悔恨和迷茫，而他們則將依據所扮演的角色對他作出相應的回應，或道歉、或寬恕，也可以認同他的感受。通過將自己的「內心世界」投射到三維空間，尤金將得以重塑自己最\u001b[01;31m\u001b[K不堪回首\u001b[m\u001b[K的經歷，而且效果會比其他形式的角色扮演治療更加徹底。如果實驗能夠成功，那些悲慘的回憶將可以通過另一種方式——一種可以獲得認可、寬恕或愛的方式來重新描述。\n"
     ]
    }
   ],
   "source": [
    "words = '''\n",
    "訴訟 灌輸 萌芽 巧取豪奪 名存實亡 盛氣凌人 雞皮疙瘩 不堪回首 \n",
    "'''\n",
    "words = words.strip().split()\n",
    "word   = words[-1]\n",
    "#print(' | '.join(zh2en(word, 35)))\n",
    "\n",
    "corpora = ['UNv1.0.en-zh.combined.txt', 'nytimes.txt', 'roclaws.zh-en.combined.txt', 'frog.zh-en.combined.txt']\n",
    "corpus = corpora[1]\n",
    "! grep -Pi -B1 -e \"$word\" $corpus --color=always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embryonic\n",
      "CPU times: user 646 ms, sys: 11.9 ms, total: 658 ms\n",
      "Wall time: 652 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'萌芽 | 幹細胞 | 初級階段 | 胚胎 | 發育階段 | 牙齦 | 大腦 | 類固醇 | 初步階段 | 孕育 | 授精 | 無性繁殖 | 動物模型 | 體外 | 性腺 | 雌激素 | 垂體 | 代謝 | 嬰兒期 | 細胞 | 乳汁 | 體細胞 | 染色體 | 失重 | 發育畸形 | 雛形 | 腎癌 | 囊腫 | 開發階段 | 現階段 | 細胞培養 | 配子 | 高級階段 | 激素 | 受精 | 先天 | 克隆人 | 生殖細胞 | 癌 | 晚期 | 人工呼吸 | 單細胞 | 分泌 | 為時尚早 | 支氣管 | 腫瘤 | 克隆 | 胚 | 已近尾聲 | 斑馬魚'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "words = '''\n",
    "embryonic \n",
    "'''\n",
    "words = words.strip().split()\n",
    "w = words[-1]; print(w)\n",
    "' | '.join(en2zh(w, n=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'初級階段 | 起步 | 沉淪 | 休眠狀態 | 消退 | 壽終正寢 | 消亡 | 牙齦 | 醞釀 | 孕育 | 發芽 | 後期 | 初具 | 苗頭 | 潛伏 | 開花 | 初創 | 慢慢 | 消散 | 深陷 | 湧現 | 無政府 | 初期 | 捲土重來 | 方興未艾'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = '''\n",
    "夠用 足夠 萬劫 不復 問題 轉換 提供 深邃 萌芽 \n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(zhSynonyms(words[-1], 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
